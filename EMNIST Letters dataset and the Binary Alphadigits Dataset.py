# -*- coding: utf-8 -*-
"""CPSC585_GP_8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ShFOLDz9nxKWAlAyUlC_wJXqTgQdIzRY

# Convolutional Neural Networks and Transfer Learning

**[CPSC 585-01 Spring 2023](https://csufullerton.instructure.com/courses/3356437/external_tools/1067388) [Project 1](https://docs.google.com/document/d/1jUl75mSMs1yVr06SLoKbJbKrufzADPAiU3lVo0JyAak/edit#heading=h.6mua4eq86gdg)**

**Authors:** *(Group 8)* Ayush Bhardwaj, Ken Cue, Chris Freeland, Gordon Huynh, Anthony Hernandez, Tina Torabinejad

This project aims to tackle a more complex character recognition problem using higher-resolution grayscale images of hand-written letters.

---

# Initialization

For this project, we import the Keras, numpy, and matplot libaries in order to build and evaluate our models and visualize the datasets.
"""

from google.colab import files
from tensorflow import keras
from sklearn.model_selection import train_test_split
from io import BytesIO

import matplotlib.pyplot as plt
import numpy as np
import random
import tensorflow as tf
import datetime

# Install localtunnel, to help display tensorboard in another tab rather than within collab
! npm install -g localtunnel

"""### Constants"""

# Constants
INPUT_SHAPE = (28, 28, 1)

"""- `INPUT_SHAPE` - This is the size of our images. If the dataset has a different shape then we will need to resize those images to this input shape.

---

# Part 1: Exploring the Simple MNIST ConvNet



In this section, we examine Chollet’s example model, and test the accuracy against the MNIST dataset.

## 1.1 - Examining the accuracy of Chollet's example model using MNIST Data
"""

# Load the MNIST data from Chollet’s MNIST notebook
(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = keras.datasets.mnist.load_data()

"""We are using Chollet's model from the [Multilayer Perceptron notebook](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter02_mathematical-building-blocks.ipynb#scrollTo=CqBQHP2sywjD)"""

# network architecture from Chollet’s notebook
chollet_model = keras.Sequential([
    keras.layers.Dense(512, activation="relu"),
    keras.layers.Dense(10, activation="softmax")
])

chollet_model.compile(
    optimizer="rmsprop",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

mnist_train_images = mnist_train_images.reshape((60000, 28 * 28))
mnist_train_images = mnist_train_images.astype("float32") / 255
mnist_test_images = mnist_test_images.reshape((10000, 28 * 28))
mnist_test_images = mnist_test_images.astype("float32") / 255

chollet_model.fit(mnist_train_images, mnist_train_labels, epochs=5, batch_size=128)

chollet_model.summary()

chollet_model_test_loss, chollet_model_test_acc = chollet_model.evaluate(mnist_test_images, mnist_test_labels)
print(f"Test Accuracy on MNIST dataset: {chollet_model_test_acc}")

"""The accuracies, that were achieved during both training and testing Chollet's model using MNIST data as input, were `~98%`

## 1.2 - Loading the EMNIST dataset

We uploaded the [EMNIST dataset](https://www.nist.gov/itl/products-and-services/emnist-dataset) to a Dropbox folder in order for Colab to automatically retrieve it to its local storage.
"""

# retrieving the dataset
!wget -O emnist_letters.npz https://www.dropbox.com/s/ndtsiqh3xhxvizz/emnist_letters.npz?dl=0

# loading from eminst_letters.npz file from the notebook's drive
# keys = { 'train_images', 'train_labels', 'validate_images', 'validate_labels', 'test_images', and 'test_labels' }
emnist_data= np.load('/content/emnist_letters.npz')

print(f"train_images shape: {emnist_data['train_images'].shape}")
print(f"train_labels shape: {emnist_data['train_labels'].shape} ")
print(f"validate_images shape: {emnist_data['validate_images'].shape} ")
print(f"validate_labels shape: {emnist_data['validate_labels'].shape} ")
print(f"test_images shape: {emnist_data['test_images'].shape} ")
print(f"test_labels shape: {emnist_data['test_labels'].shape} ")

"""We now verify that the EMNIST dataset loaded properly by displaying randomly selected items."""

emnist_train_samples = emnist_data['train_images'].shape[0]

# generating 50 random numbers between 0 and 104,000
# we will use these random numbers to verify the train_images data
random_numbers = [random.randint(0, emnist_train_samples) for number in range(20)]

# the label will be a digit, this will help us convert it to a char
# also, note that the labels are not zero-indexed, so a = 1
alphabet = '_abcdefghijklmnopqrstuvwxyz'

plt.gray()

fig, ax = plt.subplots(10, 5, figsize=(20, 40))

for num, axi in enumerate(ax.flat):
    label = np.argmax(emnist_data['train_labels'][num])
    label = alphabet[label]
    img = emnist_data['train_images'][num].reshape(28, 28)
    axi.imshow(img)
    axi.set_title(f"The actual label is: {label}")

plt.show()

"""## 1.3 - Applying the network architecture from Chollet’s MNIST notebook to the EMNIST data


"""

# normalizing train, test and validation images
emnist_train_images = emnist_data['train_images'].astype("float32") / 255
emnist_test_images = emnist_data['test_images'].astype("float32") / 255
emnist_validation_images = emnist_data['validate_images'].astype("float32") / 255

# converting labels to digits, since sparse_categorical_crossentropy does not
# use 1-hot encoding
emnist_train_labels = np.argmax(emnist_data['train_labels'], axis = 1)
emnist_test_labels = np.argmax(emnist_data['test_labels'], axis = 1)
emnist_validation_labels = np.argmax(emnist_data['validate_labels'], axis = 1)

emnist_num_classes = emnist_data['train_labels'].shape[1]  # should be 27

chollet_model_emnist = keras.Sequential([
    keras.layers.Dense(512, activation="relu"),
    keras.layers.Dense(emnist_num_classes, activation="softmax")
])

chollet_model_emnist.compile(
    optimizer="rmsprop",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

"""We first trained the model with the EMNIST dataset using the same number of epochs as in Chollet's notebook."""

chollet_model_emnist.fit(emnist_train_images, emnist_train_labels, epochs=5, batch_size=128)

chollet_model_emnist_test_loss, chollet_model_emnist_test_acc = chollet_model_emnist.evaluate(emnist_test_images, emnist_test_labels)
print(f"Test Accuracy (5 epochs): {chollet_model_emnist_test_acc}")

"""The model outputted roughly `56%` accuracy when training and testing the model using the same number of epochs. It also seems that the model has not yet converged since the loss was still going down steadily.

Thus, we tried to use more iterations to see if the model would converge (hopefully without overfitting)
"""

chollet_model_emnist = keras.Sequential([
    keras.layers.Dense(512, activation="relu"),
    keras.layers.Dense(emnist_num_classes, activation="softmax")
])

chollet_model_emnist.compile(
    optimizer="rmsprop",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

chollet_model_emnist.fit(emnist_train_images, emnist_train_labels, epochs=50, batch_size=128)

chollet_model_emnist_test_loss, chollet_model_emnist_test_acc = chollet_model_emnist.evaluate(emnist_test_images, emnist_test_labels)
print(f"test_acc: {chollet_model_emnist_test_acc}")

"""After about *50 iterations*, the training and test accuracies increased to about `~83%`.

**The accuracies that we achieved using the EMNIST dataset is lower than MNIST by significant amount.** Even by changing the number of epochs which usually increase the accuracy, we still can't get anywhere near the accuracy of MNIST data. 

We believe the difference in accuracies can be attributed to:
*   EMNIST having ***a larger and more complex set of data*** compared to MNIST.
*   The model from Chollet is not complex enough to learn the higher number of features in the EMNIST dataset.

## 1.4 - Using Simple MNIST convnet architecture on the EMNIST dataset

### Preparing the EMNIST dataset

We begin by preparing the input data so they are compatible with the model.
"""

# Model / data parameters
eminst_num_classes = emnist_data['train_labels'].shape[1]

# Make sure images have shape (28, 28, 1)
emnist_train_images_reshaped = emnist_data['train_images'].reshape(104000, 28, 28, 1)
emnist_test_images_reshaped = emnist_data['test_images'].reshape(20800, 28, 28, 1)
emnist_validation_images_reshaped = emnist_data['validate_images'].reshape(20800, 28, 28, 1)

print("train_images shape:", emnist_train_images_reshaped.shape)
print(emnist_train_images_reshaped.shape[0], "train samples")
print(emnist_test_images_reshaped.shape[0], "test samples")

# convert class vectors to binary class matrices
emnist_train_labels_mat = keras.utils.to_categorical(emnist_train_labels, emnist_num_classes)
emnist_test_labels_mat = keras.utils.to_categorical(emnist_test_labels, emnist_num_classes)
emnist_validation_labels_mat = keras.utils.to_categorical(emnist_validation_labels, emnist_num_classes)

"""### Building the Simple MNIST model

The model used below can be found [here](https://keras.io/examples/vision/mnist_convnet/).
"""

simple_mnist_model = keras.Sequential(
    [
        keras.Input(shape=INPUT_SHAPE),
        keras.layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
        keras.layers.MaxPooling2D(pool_size=(2, 2)),
        keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
        keras.layers.MaxPooling2D(pool_size=(2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dropout(0.5),
        keras.layers.Dense(eminst_num_classes, activation="softmax"),
    ]
)

simple_mnist_model.summary()

"""### Training the Simple MNIST model"""

batch_size = 128
epochs = 15

simple_mnist_model.compile(
    loss="categorical_crossentropy", 
    optimizer="adam", 
    metrics=["accuracy"]
)

simple_mnist_model.fit(
    emnist_train_images_reshaped, 
    emnist_train_labels_mat, 
    batch_size=batch_size, 
    epochs=epochs, 
    validation_data=(emnist_validation_images_reshaped, emnist_validation_labels_mat)
)

"""### Evaluating the trained model"""

score = simple_mnist_model.evaluate(emnist_test_images_reshaped, emnist_test_labels_mat, verbose=0)
print("EMNIST Test loss:", score[0])
print("EMNIST Test accuracy:", score[1])

"""The test accuracy of the EMNIST dataset in this architecture is `~93%`.

Comparing the accuracy on the Simple MNIST Convnet model with the other models above:
* The accuracy that we achieved is ***a little bit lower*** than the accuracy of MNIST dataset on Chollet's model. 
* The accuracy that we achieved is ***much higher than*** the accuracy of the EMNIST dataset that we calculated with the Dense network from Chollet above (in 1.3).

---

# Part 2: TensorBoard and Maximizing Validation Set Accuracy

## 2.5 - Adding TensorBoard support for this notebook

We have added TensorBoard to this notebook. The dashboard is displayed in the succeeding section.
"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

# DEVELOPMENT PURPOSE ONLY - Clear any logs from previous runs
# !rm -rf ./logs/

"""## 2.6 - Experimenting with alternative architectures

After experimenting with different models and testing out different hyperparameters, this section shows model that achieved the highest validation accuracy.

_Link to some of the models we have tried can be found [here](https://docs.google.com/document/d/1tmR0YeBssyluIY-ofl2_8hkn5Z6Df1Voa-4_vRmYO4U/edit?usp=sharing)._
"""

# early stopping to prevent overfitting
early_stopping = keras.callbacks.EarlyStopping(monitor="val_accuracy", min_delta=0.0001, patience=3, verbose=1, restore_best_weights=True)

emnist_num_classes = emnist_data['train_labels'].shape[1]   # should be 27

alternative_model = keras.Sequential([
    keras.Input(shape=INPUT_SHAPE),
    # data_augmentation_layer,
    keras.layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),
    keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding = 'same'),
    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),
    keras.layers.Conv2D(128, kernel_size=(3, 3), activation="relu", padding = 'valid'),
    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),
    keras.layers.Flatten(),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(32, activation ="relu"),
    keras.layers.Dense(64, activation ="relu"),
    keras.layers.Dense(128, activation ="relu"),
    keras.layers.Dense(emnist_num_classes, activation="softmax")
])

optimizer = keras.optimizers.Adam(learning_rate=0.001)

alternative_model.compile(
    loss="categorical_crossentropy",
    optimizer=optimizer, 
    metrics=["accuracy"]
)

alternative_model.summary()

# using TensorBoard with Keras Model.fit
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

batch_size = 256
epochs = 30

alternative_model.fit(
    emnist_train_images_reshaped, 
    emnist_train_labels_mat, 
    epochs=epochs, 
    validation_data=(emnist_validation_images_reshaped, emnist_validation_labels_mat), 
    callbacks=[tensorboard_callback, early_stopping]
)

# Commented out IPython magic to ensure Python compatibility.
#start tensorboard
# %tensorboard --logdir logs/fit

# code to get url for tensorboard, which we can paste into another tab
# use this if you want to view tensorboard in another tab
LOG_DIR = './log'
get_ipython().system_raw(
    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'
    .format(LOG_DIR)
)

# Tunnel port 6006 (TensorBoard assumed running)
get_ipython().system_raw('lt --port 6006 >> url.txt 2>&1 &')


# Get url
! cat url.txt

"""## 2.7 - Evaluating our alternative model"""

# storing our model weights so we can easily recover them in case of accidental re-training
alternative_model.save_weights('/content/models/alternative_model_emnist_weights')

score = alternative_model.evaluate(emnist_test_images_reshaped, emnist_test_labels_mat, verbose=0)
print("Alternative Model Test loss:", score[0])
print("Alternative Model Test accuracy:", score[1])

"""After testing out different models (with various layers) and different hyperparameters. The model that performed the best had a test accuracy of about `94%`. This model also had `~93.8%` validation accuracy during training.

---

# Part 3: Transfer Learning

In this section, we will be using the transfer learning workflow to test the Binary Alphadigits dataset on our model from Part 2.5

## 3.8 - Preparing the Binary Alphadigits dataset

Similar to what we did with the EMNIST dataset above, we have uploaded the [Binary Alphadigits](https://cs.nyu.edu/~roweis/data.html) [dataset](https://drive.google.com/file/d/1C1S0lSR140MRXil035PTd5KbfTQd2hwT/view?usp=sharing) to a dropbox folder so we can conveniently retrieve it here.
"""

# uploaded the binaryalphadigs.npz file in a public dropbox folder
# retrieving it here
!wget -O binaryalphadigs.npz https://www.dropbox.com/s/9ap8bqynti14urx/binaryalphadigs.npz?dl=0

# Load the Binary Alphadigits dataset into our local Colab drive
binaryalphadigs_data= np.load('/content/binaryalphadigs.npz')

from google.colab import drive
drive.mount('/content/drive')

print(f"Images shape: {binaryalphadigs_data['images'].shape}")
print(f"Labels shape: {binaryalphadigs_data['labels'].shape}")

# Ensure the data was loaded properly by visualizing a sample
print(f"Image Shape: {binaryalphadigs_data['images'][0].shape}")
label = np.argmax(binaryalphadigs_data['labels'][0])
label = alphabet[label]
img = binaryalphadigs_data['images'][0].reshape(20, 16)
print(f"Label: {label}")
plt.matshow(img, cmap='gray')
plt.show()

"""We only need to print one here, since we are just looking at what the images look like as well and confirm that we had loaded the data without corruption.

Next, since the images in the dataset are `16x20`, we have to resize these images so it would fit the `(28, 28, 1)` input size of the model.
"""

# Resize the Binary Alphadigits images the sizes of the EMNIST dataset (28x28)
resized_binaryalphadigs_data = {
    'images': [],
    'labels': []
}

for idx, img in enumerate(binaryalphadigs_data['images']):
    resized_binaryalphadigs_data['labels'].append(binaryalphadigs_data['labels'][idx])
    resized_binaryalphadigs_data['images'].append(tf.image.resize_with_pad(img.reshape(20, 16, 1), 28, 28))

# convert to numpy arrays
resized_binaryalphadigs_data['labels'] = np.array(resized_binaryalphadigs_data['labels'])
resized_binaryalphadigs_data['images'] = np.array(resized_binaryalphadigs_data['images'])

# Confirm that images were resized
label = np.argmax(resized_binaryalphadigs_data['labels'][0])
label = alphabet[label]
img = resized_binaryalphadigs_data['images'][0]
print(f"Label: {label}")
plt.matshow(img, cmap='gray')
plt.show()

"""The images have been properly resized, so now we are able to perform our analyses.

## 3.9 - Testing the Binary Alphadigits dataset against our alternative model

Does the alternative model that we trained in Part 2 with the EMNIST model recognize letters from the Binary Alphadigits dataset?
"""

# Test if our model can read the binary alphadigits dataset
score = alternative_model.evaluate(resized_binaryalphadigs_data['images'], resized_binaryalphadigs_data['labels'], verbose=0)
print("Test loss (using Binary Alphadigits dataset):", score[0])
print("Test accuracy (using Binary Alphadigits dataset):", score[1])

"""The model we trained in part 2 is capable of recognizing the letters in the Binary Alphadigits dataset. However, the accuracy is lower (`~84%` whereas it achieved `~94%` on the EMNIST test set). The loss on this dataset is significantly higher as well.

The accuracy we achieved is not terrible considering it's a completely different dataset that our model was never trained for. The fact that it can recognize the letters with more than `80%` accuracy is good, but we may be able to improve on it.

## 3.10 - Improving the performance on the Binary Alphadigits dataset by adding additional trainable layers and fine-tuning the network

In this section, we will see if we can improve our model's accuracy by following the transfer learning workflow as described [here](https://keras.io/guides/transfer_learning/).

We note that the Binary Alphadigits dataset is much smaller than the EMNIST dataset (`~1k` vs `>100k`).
"""

# Split the Binary Alphadigits Dataset into train and test dataset
ba_train_images, ba_test_images, ba_train_labels, ba_test_labels = train_test_split(
    resized_binaryalphadigs_data['images'], 
    resized_binaryalphadigs_data['labels'] , 
    test_size=0.2, 
    random_state=42
)

ba_num_labels = resized_binaryalphadigs_data['labels'].shape[1] # should be 27

"""### Freezing the Model"""

base_model = keras.models.clone_model(alternative_model)

# Making sure we have the weights from part 2 in the base model
base_model.load_weights('/content/models/alternative_model_emnist_weights') 

# We remove the classification layer
base_model.pop()

# Freeze the base model
base_model.trainable = False

base_model.summary()

"""### Adding Additional Layers"""

# Create a new model on top of base model from Part 2.5 and adding new layers
tl_model = keras.Sequential([
    base_model,
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dense(ba_num_labels, activation="softmax")
])

optimizer = keras.optimizers.Adam(learning_rate=0.001)1

tl_model.compile(
    loss="categorical_crossentropy", 
    optimizer=optimizer, 
    metrics=["accuracy"]
)

batch_size = 64
num_epochs = 30
val_split = 0.2

tl_model.fit(
    ba_train_images, 
    ba_train_labels, 
    epochs=num_epochs, 
    batch_size=batch_size, 
    validation_split=val_split
)

score = tl_model.evaluate(ba_test_images, ba_test_labels, verbose=0)
print("Transfer Learning Model Test Loss:", score[0])
print("Transfer Learning Model Test Accuracy:", score[1])

"""By adding an additional densely connected NN layer, we were able to improve the accuracy a bit to approximately `88%`.

### Fine Tuning
"""

# Unfreeze the base model
tl_model.trainable = True

for layer in tl_model.layers:
  assert layer.trainable == True   # make sure inner layers are also trainable

# early_stopping_for_loss = keras.callbacks.EarlyStopping(monitor="val_loss", min_delta=0, patience=3, mode="auto", verbose=1, restore_best_weights=True)

tl_model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-5), 
    loss='categorical_crossentropy', 
    metrics=['accuracy']
) # Very low learning rate

# We use the same num_epochs, batch_size and val_split values as in our previous fit
tl_model.fit(
    ba_train_images, 
    ba_train_labels, 
    epochs=num_epochs, 
    batch_size=batch_size, 
    validation_split=val_split, 
    # callbacks=[early_stopping_for_loss]
)

score = tl_model.evaluate(ba_test_images, ba_test_labels, verbose=0)
print("Test Loss (after Fine Tuning):", score[0])
print("Test Accuracy (after Fine Tuning):", score[1])

"""We were able to see a bit of improvement (approx `0.5%`) to the accuracy after fine tuning. There was also a minimal change in the loss. We can attribute the small but incremental improvement to the very small learning rate used.

## 3.11 - Comparing the performance of the model built by transfer learning vs. the performance of a brand-new model trained only on the Binary AlphaDigits dataset

### Building a brand-new model for training only the Binary AlphaDigits dataset
"""

# define the binary alphadigits dataset
ba_model = keras.Sequential([
    keras.Input(shape=INPUT_SHAPE),
    keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),
    keras.layers.Conv2D(128, kernel_size=(3, 3), activation="relu", padding='valid'),
    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),
    keras.layers.Flatten(),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(64, activation="relu"),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.Dense(ba_num_labels, activation="softmax")
])

optimizer = keras.optimizers.Adam()

ba_model.compile(
    loss="categorical_crossentropy", 
    optimizer=optimizer, 
    metrics=["accuracy"])

ba_model.summary()

print("\n\n")

batch_size = 64
num_epochs = 30
val_split = 0.1

ba_model.fit(ba_train_images, ba_train_labels, epochs=num_epochs, batch_size=batch_size, validation_split=val_split)

"""### Comparing the Performances"""

score = ba_model.evaluate(ba_test_images, ba_test_labels, verbose=0)
print("New Model Test Loss:", score[0])
print("New Model Test Accuracy:", score[1])

print("\n")

score = tl_model.evaluate(ba_test_images, ba_test_labels, verbose=0)
print("Transfer Learning Model Test Loss (after Fine Tuning):", score[0])
print("Transfer Learning Model Test Accuracy (after Fine Tuning):", score[1])

"""__Loss and Accuracy on the test data from the model that underwent the transfer learning workflow is better than the model that learned only using the Binary AlphaDigits dataset.__

The results show that the training done using EMNIST data did help since we had significantly larger amount of data to learn from. Combining it with a bit of training using the Binary AlphaDigits dataset, we were even able to see an incremental improvements on loss and accuracy.
"""